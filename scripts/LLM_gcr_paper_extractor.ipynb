{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Information Extractor \n",
    "import os\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "import anthropic\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import csv\n",
    "import json\n",
    "from io import StringIO\n",
    "import hashlib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/maximilianroessler/Documents/Hobby/Volunteering/ALLFED/LiteraryReview/gcr-resilience-map/scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Anthropic Client\n",
    "\n",
    "# read the API key from the file    \n",
    "with open(\"../config/api_key.txt\", 'r') as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "# API Key\n",
    "api_key = api_key  # Replace with your actual API key or use environment variables\n",
    "\n",
    "# Initialize Anthropic client\n",
    "client = anthropic.Anthropic(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDF Processing Functions\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_with_claude(text: str, query: str, temperature: float = 0, max_tokens: int = 1000) -> str:\n",
    "    \"\"\"Process text with Claude model using prefix caching\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token_count = len(encoding.encode(text))\n",
    "    token_count = int(token_count * 1.1)\n",
    "    print(f\"Token count is approximately {token_count}\")\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        system=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are an AI assistant tasked with analyzing documents.\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Document content:\\n{text}\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Log cache information if available\n",
    "    if hasattr(response, 'usage'):\n",
    "        print(f\"API Response Token Usage:\")\n",
    "        print(f\"  - Total input tokens: {response.usage.input_tokens}\")\n",
    "        print(\n",
    "            f\"  - Cache creation tokens: {getattr(response.usage, 'cache_creation_input_tokens', 0)}\")\n",
    "        print(\n",
    "            f\"  - Cache read tokens: {getattr(response.usage, 'cache_read_input_tokens', 0)}\")\n",
    "\n",
    "        # Calculate percentage saved if using cache\n",
    "        cache_read = getattr(response.usage, 'cache_read_input_tokens', 0)\n",
    "        if cache_read > 0:\n",
    "            total_possible = response.usage.input_tokens + cache_read\n",
    "            percentage_saved = (cache_read / total_possible) * 100\n",
    "            print(\n",
    "                f\"  - Approximate cache savings: {percentage_saved:.1f}% of input tokens\")\n",
    "\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extraction prompt\n",
    "extraction_query = \"\"\"I need you to analyze the provided research paper and extract specific information about regional resilience to catastrophic risks. Our research question is: \"What specific geographical, institutional, and infrastructural factors have been empirically or theoretically identified as enhancing regional resilience to nuclear winter, large magnitude volcanic eruptions, extreme pandemics, and infrastructure collapse catastrophes, and how do these resilience factors vary across catastrophe types?\"\n",
    "\n",
    "After analyzing the paper thoroughly, provide your output in a single row CSV format with the following structure:\n",
    "\n",
    "1. paper_citation: Full citation (author, year, title)\n",
    "2. publication_type: [Journal article/Preprint/Report/Book chapter]\n",
    "3. gcr_types: Types of catastrophic risks addressed [Nuclear/Volcanic/Asteroid/Infrastructure/Pandemic/Climate/Multiple]\n",
    "4. geographic_focus: [Global/Regional/National/Local/Islands - specify]\n",
    "5. regions_compared: [Yes/No] with brief description if yes\n",
    "6. geographic_factors: List key geographic factors (location, climate, resources, etc.)\n",
    "7. institutional_factors: List key institutional factors (governance, policies, social systems, etc.)\n",
    "8. infrastructural_factors: List key infrastructure factors (energy, food, communications, etc.)\n",
    "9. other_resilience_factors: Any resilience factors not fitting above categories\n",
    "10. study_approach: [Model/Empirical/Review/Case study/Theoretical]\n",
    "11. evidence_strength: [Low/Medium/High] with brief justification\n",
    "12. evidence_causal: [TRUE/FALSE] for direct causal evidence\n",
    "13. evidence_predictive: [TRUE/FALSE] for predictive evidence\n",
    "14. evidence_correlational: [TRUE/FALSE] for correlational evidence\n",
    "15. evidence_theoretical: [TRUE/FALSE] for theoretical/expert opinion\n",
    "16. evidence_case_study: [TRUE/FALSE] for case study observations\n",
    "17. evidence_model: [TRUE/FALSE] for model-based projections\n",
    "18. validation_external: [TRUE/FALSE] for external validation against outcomes\n",
    "19. validation_alternative: [TRUE/FALSE] for validation against alternative datasets\n",
    "20. validation_temporal: [TRUE/FALSE] for validation across multiple time periods\n",
    "21. validation_cross_regional: [TRUE/FALSE] for cross-regional validation\n",
    "22. validation_none: [TRUE/FALSE] if no validation attempted\n",
    "23. counterfactual_robust: [TRUE/FALSE] for robust counterfactual analysis\n",
    "24. counterfactual_limited: [TRUE/FALSE] for limited counterfactual discussion\n",
    "25. counterfactual_none: [TRUE/FALSE] if no counterfactuals considered\n",
    "26. limitations_thorough: [TRUE/FALSE] if authors thoroughly address limitations\n",
    "27. limitations_limited: [TRUE/FALSE] if limited discussion of limitations\n",
    "28. limitations_none: [TRUE/FALSE] if no significant discussion of limitations\n",
    "29. confidence_assessment: [High/Medium/Low/Very low] for key resilience factors\n",
    "30. evidence_gaps: Brief description of critical missing validation elements\n",
    "31. resilience_phase: [Preparedness/Robustness/Recovery/Adaptation]\n",
    "32. implemented_measures: Brief description of measures already implemented (if any)\n",
    "33. proposed_measures: Brief description of proposed measures (if any)\n",
    "34. main_resilience_factors: Brief summary of main resilience-enhancing factors\n",
    "35. differential_effectiveness: [Yes/No] with description if factors vary across GCR types\n",
    "36. resilience_tradeoffs: [Yes/No] with description of any identified trade-offs\n",
    "37. vulnerable_resilient_regions: List of particularly vulnerable or resilient regions identified\n",
    "38. overall_relevance: [Low/Medium/High] relevance to our research question\n",
    "39. key_quotes: 1-2 most relevant quotes supporting findings\n",
    "40. additional_notes: Any other important observations\n",
    "\n",
    "For text fields, place the content in double quotes to properly handle any commas. For boolean fields, use TRUE or FALSE. For fields with multiple options like evidence types, mark TRUE for all that apply.\n",
    "\n",
    "Please analyze the paper thoroughly before extracting the information. Respond with ONLY the CSV row (no column headers).\"\"\"\n",
    "\n",
    "# Define the column names based on the structure\n",
    "extraction_columns = [\n",
    "    \"paper_citation\", \"publication_type\", \"gcr_types\", \"geographic_focus\", \n",
    "    \"regions_compared\", \"geographic_factors\", \"institutional_factors\", \"infrastructural_factors\", \n",
    "    \"other_resilience_factors\", \"study_approach\", \"evidence_strength\", \n",
    "    \"evidence_causal\", \"evidence_predictive\", \"evidence_correlational\", \n",
    "    \"evidence_theoretical\", \"evidence_case_study\", \"evidence_model\", \n",
    "    \"validation_external\", \"validation_alternative\", \"validation_temporal\", \n",
    "    \"validation_cross_regional\", \"validation_none\", \"counterfactual_robust\", \n",
    "    \"counterfactual_limited\", \"counterfactual_none\", \"limitations_thorough\", \n",
    "    \"limitations_limited\", \"limitations_none\", \"confidence_assessment\", \n",
    "    \"evidence_gaps\", \"resilience_phase\", \"implemented_measures\", \n",
    "    \"proposed_measures\", \"main_resilience_factors\", \"differential_effectiveness\", \n",
    "    \"resilience_tradeoffs\", \"vulnerable_resilient_regions\", \"overall_relevance\", \n",
    "    \"key_quotes\", \"additional_notes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## relevance prompt\n",
    "\n",
    "# prompt\n",
    "relevance_query = \"\"\"I need you to analyze the provided research paper and extract specific information about regional resilience to catastrophic risks. Our research question is: \"What specific geographical, institutional, and infrastructural factors have been empirically or theoretically identified as enhancing regional resilience to nuclear winter, large magnitude volcanic eruptions, extreme pandemics, and infrastructure collapse catastrophes, and how do these resilience factors vary across catastrophe types?\"\n",
    "\n",
    "After analyzing the paper thoroughly, provide your output in a single row CSV format with the following structure:\n",
    "\n",
    "1. serious_weakness: Does this paper exhibit serious methodological weaknesses? [TRUE/FALSE]\n",
    "\n",
    "For text fields, place the content in double quotes to properly handle any commas. For boolean fields, use TRUE or FALSE. For fields with multiple options like evidence types, mark TRUE for all that apply.\n",
    "\n",
    "Please analyze the paper thoroughly before extracting the information. Respond with ONLY the CSV row (no column headers).\"\"\"\n",
    "\n",
    "# Define the column names based on the structure\n",
    "relevance_columns = [\n",
    "    \"serious_weakness\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_csv_response(response_text, columns):\n",
    "    \"\"\"Parse the CSV response from Claude and return a dictionary with column names as keys\"\"\"\n",
    "    # Clean the response text\n",
    "    clean_text = response_text.strip()\n",
    "\n",
    "    # If there are multiple lines, take only the CSV line\n",
    "    if \"\\n\" in clean_text:\n",
    "        # Find the line that has the most commas (likely the CSV data)\n",
    "        lines = clean_text.split('\\n')\n",
    "        clean_text = max(lines, key=lambda x: x.count(','))\n",
    "\n",
    "    # Parse CSV using the csv module which handles quoted fields properly\n",
    "    reader = csv.reader(StringIO(clean_text))\n",
    "    try:\n",
    "        row = next(reader)\n",
    "        # Map values to column names\n",
    "        result = {col: val for col, val in zip(columns, row)}\n",
    "        return result\n",
    "    except StopIteration:\n",
    "        # If parsing fails, return the original text\n",
    "        return {\"error\": \"Failed to parse CSV response\", \"original_text\": clean_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing s13561-023-00428-9.pdf for extraction...\n",
      "Extracted 64009 characters from PDF.\n",
      "Token count is approximately 17781\n",
      "API Response Token Usage:\n",
      "  - Total input tokens: 943\n",
      "  - Cache creation tokens: 18351\n",
      "  - Cache read tokens: 0\n",
      "Received response of length 2833\n",
      "Successfully processed s13561-023-00428-9.pdf for extraction\n",
      "Processing s13561-023-00428-9.pdf for relevance...\n",
      "Token count is approximately 17781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 1/1 [00:20<00:00, 20.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response Token Usage:\n",
      "  - Total input tokens: 204\n",
      "  - Cache creation tokens: 0\n",
      "  - Cache read tokens: 18351\n",
      "  - Approximate cache savings: 98.9% of input tokens\n",
      "Received response of length 5\n",
      "Successfully processed s13561-023-00428-9.pdf for relevance\n",
      "Extraction results saved to gcr_resilience_extraction_results.csv and gcr_resilience_extraction_results_20250413_200146.csv\n",
      "Relevance results saved to gcr_resilience_relevance_results.csv and gcr_resilience_relevance_results_20250413_200146.csv\n",
      "Extraction results:\n",
      "                                      paper_citation publication_type  \\\n",
      "0  Da'ar, O. B., & Kalmey, F. (2023). The level o...  Journal article   \n",
      "\n",
      "  gcr_types geographic_focus  \\\n",
      "0  Pandemic           Global   \n",
      "\n",
      "                                    regions_compared  \\\n",
      "0  Yes, WHO regions compared (Africa, Americas, E...   \n",
      "\n",
      "                  geographic_factors  \\\n",
      "0  Geographic location (WHO regions)   \n",
      "\n",
      "                               institutional_factors  \\\n",
      "0  Governance effectiveness, health financing, pu...   \n",
      "\n",
      "                             infrastructural_factors other_resilience_factors  \\\n",
      "0  Supply chain capacity (medicines and technolog...                            \n",
      "\n",
      "  study_approach  ... implemented_measures proposed_measures  \\\n",
      "0      Empirical  ...         Preparedness                     \n",
      "\n",
      "                             main_resilience_factors  \\\n",
      "0  Strengthening supply chain capacity, health fi...   \n",
      "\n",
      "                          differential_effectiveness  \\\n",
      "0  Supply chain capacity, health financing, gover...   \n",
      "\n",
      "                                resilience_tradeoffs  \\\n",
      "0  Yes, effects of health systems building blocks...   \n",
      "\n",
      "                        vulnerable_resilient_regions  \\\n",
      "0  Yes, high-income countries showed complacency ...   \n",
      "\n",
      "                                   overall_relevance key_quotes  \\\n",
      "0  Africa was least prepared across all regions; ...       High   \n",
      "\n",
      "                                    additional_notes                filename  \n",
      "0  \\The results show that increases in effective ...  s13561-023-00428-9.pdf  \n",
      "\n",
      "[1 rows x 41 columns]\n",
      "\n",
      "Relevance results:\n",
      "  serious_weakness                filename\n",
      "0            FALSE  s13561-023-00428-9.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"pdf\"  # Directory containing PDF files\n",
    "temperature = 0   # Keep it as deterministic as possible\n",
    "max_tokens = 4000  # Increased token limit for more detailed responses\n",
    "cache_dir = \"prompt_cache\"  # Directory for caching prompts and responses\n",
    "\n",
    "# Define configuration for extraction and relevance processes\n",
    "process_types = ['extraction', 'relevance']\n",
    "config = {\n",
    "    'extraction': {\n",
    "        'output_file': \"gcr_resilience_extraction_results.csv\",\n",
    "        'cache_file': os.path.join(cache_dir, \"extraction_prompt_cache.json\"),\n",
    "        'query': extraction_query,\n",
    "        'columns': extraction_columns\n",
    "    },\n",
    "    'relevance': {\n",
    "        'output_file': \"gcr_resilience_relevance_results.csv\",\n",
    "        'cache_file': os.path.join(cache_dir, \"relevance_prompt_cache.json\"),\n",
    "        'query': relevance_query,\n",
    "        'columns': relevance_columns\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# Initialize caches, results, and processed files\n",
    "caches = {}\n",
    "results = {}\n",
    "processed_files = {}\n",
    "\n",
    "# Load caches and existing results\n",
    "for process_type in process_types:\n",
    "    # Load cache\n",
    "    cache_file = config[process_type]['cache_file']\n",
    "    caches[process_type] = {}\n",
    "    if os.path.exists(cache_file):\n",
    "        try:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                caches[process_type] = json.load(f)\n",
    "            print(f\"Loaded {len(caches[process_type])} cached {process_type} responses\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {process_type} cache: {str(e)}\")\n",
    "    \n",
    "    # Load results\n",
    "    output_file = config[process_type]['output_file']\n",
    "    results[process_type] = []\n",
    "    processed_files[process_type] = set()\n",
    "    if os.path.exists(output_file):\n",
    "        try:\n",
    "            df = pd.read_csv(output_file)\n",
    "            results[process_type] = df.to_dict('records')\n",
    "            processed_files[process_type] = set(df['filename'].tolist())\n",
    "            print(f\"Loaded {len(results[process_type])} existing {process_type} results\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing {process_type} results: {str(e)}\")\n",
    "\n",
    "# Process PDFs\n",
    "pdf_files = list(Path(pdf_dir).glob('*.pdf'))\n",
    "\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "    # Extract text only once for both queries\n",
    "    text = None\n",
    "    \n",
    "    # Process each configuration\n",
    "    for process_type in process_types:\n",
    "        current_config = config[process_type]\n",
    "        current_cache = caches[process_type]\n",
    "        current_results = results[process_type]\n",
    "        current_processed_files = processed_files[process_type]\n",
    "        \n",
    "        if pdf_path.name not in current_processed_files:\n",
    "            try:\n",
    "                print(f\"Processing {pdf_path.name} for {process_type}...\")\n",
    "                \n",
    "                # Extract text if not already done\n",
    "                if text is None:\n",
    "                    text = extract_text_from_pdf(str(pdf_path))\n",
    "                    print(f\"Extracted {len(text)} characters from PDF.\")\n",
    "                \n",
    "                # Create cache key\n",
    "                cache_key = hashlib.md5((text + current_config['query']).encode()).hexdigest()\n",
    "                \n",
    "                # Check for cached response\n",
    "                if cache_key in current_cache:\n",
    "                    print(f\"Using cached response for {pdf_path.name} ({process_type})\")\n",
    "                    response = current_cache[cache_key]\n",
    "                else:\n",
    "                    # Process with Claude\n",
    "                    response = process_with_claude(text, current_config['query'], temperature, max_tokens)\n",
    "                    print(f\"Received response of length {len(response)}\")\n",
    "                    \n",
    "                    # Cache the response\n",
    "                    current_cache[cache_key] = response\n",
    "                    \n",
    "                    # Save cache after each new response\n",
    "                    with open(current_config['cache_file'], 'w') as f:\n",
    "                        json.dump(current_cache, f)\n",
    "                \n",
    "                # Parse the CSV response\n",
    "                parsed_result = parse_csv_response(response, current_config['columns'])\n",
    "                \n",
    "                # Add the filename for reference\n",
    "                parsed_result['filename'] = pdf_path.name\n",
    "                \n",
    "                # Add to results\n",
    "                current_results.append(parsed_result)\n",
    "                \n",
    "                # Save intermediate results\n",
    "                interim_df = pd.DataFrame(current_results)\n",
    "                interim_df.to_csv(current_config['output_file'], index=False)\n",
    "                \n",
    "                print(f\"Successfully processed {pdf_path.name} for {process_type}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdf_path.name} for {process_type}: {str(e)}\")\n",
    "                # Add error record\n",
    "                error_result = {\n",
    "                    \"error\": str(e),\n",
    "                    \"filename\": pdf_path.name\n",
    "                }\n",
    "                current_results.append(error_result)\n",
    "                \n",
    "                # Save intermediate results even after errors\n",
    "                interim_df = pd.DataFrame(current_results)\n",
    "                interim_df.to_csv(current_config['output_file'], index=False)\n",
    "        else:\n",
    "            print(f\"Skipping already processed file for {process_type}: {pdf_path.name}\")\n",
    "\n",
    "# Create final DataFrames from the results\n",
    "extraction_df = pd.DataFrame(results['extraction'])\n",
    "relevance_df = pd.DataFrame(results['relevance'])\n",
    "\n",
    "# Add timestamp for versioned outputs\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "versioned_extraction_csv = f\"{os.path.splitext(config['extraction']['output_file'])[0]}_{timestamp}.csv\"\n",
    "versioned_relevance_csv = f\"{os.path.splitext(config['relevance']['output_file'])[0]}_{timestamp}.csv\"\n",
    "\n",
    "# Save versioned outputs\n",
    "extraction_df.to_csv(config['extraction']['output_file'], index=False)\n",
    "extraction_df.to_csv(versioned_extraction_csv, index=False)\n",
    "relevance_df.to_csv(config['relevance']['output_file'], index=False)\n",
    "relevance_df.to_csv(versioned_relevance_csv, index=False)\n",
    "\n",
    "print(f\"Extraction results saved to {config['extraction']['output_file']} and {versioned_extraction_csv}\")\n",
    "print(f\"Relevance results saved to {config['relevance']['output_file']} and {versioned_relevance_csv}\")\n",
    "\n",
    "# Display results\n",
    "print(\"Extraction results:\")\n",
    "print(extraction_df.head())\n",
    "print(\"\\nRelevance results:\")\n",
    "print(relevance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate for GitHub\n"
     ]
    }
   ],
   "source": [
    "print(\"Validate for GitHub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resilience_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
