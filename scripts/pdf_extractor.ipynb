{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Information Extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "import anthropic\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Anthropic Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key\n",
    "api_key = 'HAHA, SURELY NOT ON A PUBLIC REPOSITORY'\n",
    "\n",
    "# Initialize Anthropic client\n",
    "client = anthropic.Anthropic(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def process_with_claude(text: str, query: str, temperature: float = 0, max_tokens: int = 1000) -> str:\n",
    "    \"\"\"Process text with Claude model\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token_count = len(encoding.encode(text))\n",
    "    token_count = int(token_count * 1.1)\n",
    "    print(f\"token count is {token_count}\")\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Based on the following text, {query}\\n\\nText: {text}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"I need you to extract information from a research paper for a systematic literature review on regional resilience to catastrophic risks. Our research question is: What specific geographical, institutional, and infrastructural factors have been empirically or theoretically identified as enhancing regional resilience to nuclear winter, large magnitude volcanic eruptions, extreme pandemics, and infrastructure collapse catastrophes, and how do these resilience factors vary across catastrophe types?\n",
    "After analyzing the paper, provide your output in CSV format with the following columns, without repeating the column names:\n",
    "paper_id_citation,publication_type,gcr_types_addressed,geographic_focus,regions_compared,geographic_factors,institutional_factors,infrastructural_factors,other_resilience_factors,study_approach,evidence_strength,evidence_type_direct_causal,evidence_type_predictive,evidence_type_correlational,evidence_type_theoretical,evidence_type_case_study,evidence_type_model_based,validation_external,validation_alternative_datasets,validation_multiple_periods,validation_cross_regional,validation_none,counterfactual_robust,counterfactual_limited,counterfactual_none,limitations_thorough,limitations_limited,limitations_none,confidence_assessment,key_evidence_gaps,resilience_phase,measures_implemented,proposed_measures,main_resilience_factors,differential_effectiveness,resilience_tradeoffs,vulnerable_resilient_regions,overall_relevance,key_supporting_quotes,additional_notes,evidence_type_causal,evidence_type_correlation,evidence_type_theoretical_simulation,evidence_type_expert_opinion,evidence_type_case_study_no_controls,scale_gcr_magnitude,scale_smaller_with_scaleup,scale_implicit_smallscale,scale_unclear,generalizability_geographic_context,generalizability_time_period,generalizability_single_disaster,generalizability_appropriate_caveats,limitations_correlation_causation,limitations_extrapolation,limitations_theoretical_empirical,limitations_proxy_measures,limitations_cherry_picking,limitations_side_effects,limitations_implementation,limitations_other,gcr_relevance_rating,gcr_relevance_justification\n",
    "For the evidence type, validation approach, counterfactual analysis, limitations acknowledgment, and critical evaluation checklist sections, use TRUE or FALSE to indicate which options apply.\n",
    "For text fields, place the content in double quotes to properly handle any commas in the text.\n",
    "Please analyze the paper thoroughly before extracting information according to this template. Answer with just the values of the csv\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "pdf_dir = \"pdf\"  # Directory containing PDF files\n",
    "temperature = 0 # keep it as deterministic as possible\n",
    "max_tokens = 1000\n",
    "output_csv = \"extraction_results.csv\"\n",
    "\n",
    "# Process PDFs\n",
    "results = []\n",
    "pdf_files = list(Path(pdf_dir).glob('*.pdf'))\n",
    "\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "    try:\n",
    "        text = extract_text_from_pdf(str(pdf_path))\n",
    "        response = \"test\"#process_with_claude(text, query, temperature, max_tokens)\n",
    "        \n",
    "        results.append(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path.name}: {str(e)}\")\n",
    "\n",
    "# Save results to CSV\n",
    "print(results)\n",
    "# Define the column names based on the query structure\n",
    "columns = [\n",
    "    \"paper_id_citation\", \"publication_type\", \"gcr_types_addressed\", \"geographic_focus\", \n",
    "    \"regions_compared\", \"geographic_factors\", \"institutional_factors\", \"infrastructural_factors\", \n",
    "    \"other_resilience_factors\", \"study_approach\", \"evidence_strength\", \n",
    "    \"evidence_type_direct_causal\", \"evidence_type_predictive\", \"evidence_type_correlational\", \n",
    "    \"evidence_type_theoretical\", \"evidence_type_case_study\", \"evidence_type_model_based\", \n",
    "    \"validation_external\", \"validation_alternative_datasets\", \"validation_multiple_periods\", \n",
    "    \"validation_cross_regional\", \"validation_none\", \"counterfactual_robust\", \n",
    "    \"counterfactual_limited\", \"counterfactual_none\", \"limitations_thorough\", \n",
    "    \"limitations_limited\", \"limitations_none\", \"confidence_assessment\", \n",
    "    \"key_evidence_gaps\", \"resilience_phase\", \"measures_implemented\", \n",
    "    \"proposed_measures\", \"main_resilience_factors\", \"differential_effectiveness\", \n",
    "    \"resilience_tradeoffs\", \"vulnerable_resilient_regions\", \"overall_relevance\", \n",
    "    \"key_supporting_quotes\", \"additional_notes\", \"evidence_type_causal\", \n",
    "    \"evidence_type_correlation\", \"evidence_type_theoretical_simulation\", \n",
    "    \"evidence_type_expert_opinion\", \"evidence_type_case_study_no_controls\", \n",
    "    \"scale_gcr_magnitude\", \"scale_smaller_with_scaleup\", \"scale_implicit_smallscale\", \n",
    "    \"scale_unclear\", \"generalizability_geographic_context\", \"generalizability_time_period\", \n",
    "    \"generalizability_single_disaster\", \"generalizability_appropriate_caveats\", \n",
    "    \"limitations_correlation_causation\", \"limitations_extrapolation\", \n",
    "    \"limitations_theoretical_empirical\", \"limitations_proxy_measures\", \n",
    "    \"limitations_cherry_picking\", \"limitations_side_effects\", \"limitations_implementation\", \n",
    "    \"limitations_other\", \"gcr_relevance_rating\", \"gcr_relevance_justification\"\n",
    "]\n",
    "\n",
    "results =[\"\"\"Da'ar and Kalmey (2023),journal article,extreme pandemics,global,multiple regions,\\\"\"\\\"\"\\\"\"geographic factors not directly addressed\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"effective governance, health financing, communication infrastructure\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"supply chain capacity for medicines and technologies, health workforce (doctors and nurses per 1000 population), hospital beds per 1000 population\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"Sustainable Development Goals (SDGs), Human Development Index (HDI), income level\\\"\"\\\"\"\\\"\",quantitative analysis,MEDIUM,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,MEDIUM,\\\"\"\\\"\"\\\"\"Need for more direct causal evidence on how health system factors translate to pandemic resilience\\\"\"\\\"\"\\\"\",preparedness,\\\"\"\\\"\"\\\"\"Not directly addressed\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"Strengthening supply chain capacity, health financing, communication infrastructure; maintaining health workforce and services; boosting SDGs particularly health-related sub-scales; curbing complacency in high-income countries\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"Supply chain capacity, effective governance, health financing, and SDGs were most significant for preparedness\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"Effects of health system building blocks were considerably larger for countries with higher levels of preparedness\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"Complacency in high-income countries can reduce preparedness despite resource advantages\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"African region was least prepared; Americas, European, and Southeast Asia regions had higher preparedness\\\"\"\\\"\"\\\"\",HIGH,\\\"\"\\\"\"\\\"\"The positive gradient trends signaled a sense of capacity on the part of countries with higher global health security.\\\"\" \\\"\"The effects of SDGs were greater for countries with higher levels of preparedness to health risks.\\\"\" \\\"\"Relative to poor countries, middle- and high-income countries had lower levels of preparedness to health risks, an indication of a sense of complacency.\\\"\"\\\"\"\\\"\",\\\"\"\\\"\"\\\"\"Study examines differential effects of health system building blocks and socioeconomic factors on pandemic preparedness across 195 countries, comparing pre-pandemic (2019) and pandemic (2021) periods\\\"\"\\\"\"\\\"\",FALSE,TRUE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,HIGH,\\\"\"\\\"\"\\\"\"The paper directly examines factors affecting preparedness for extreme pandemics across multiple regions, with quantitative analysis of 195 countries. It identifies specific institutional and infrastructural factors that enhance resilience, showing how these vary across different levels of preparedness.\\\"\"\\\"\"\\\"\"\"\"]\n",
    "\n",
    "# Process the results to create a proper DataFrame with the defined columns\n",
    "processed_results = []\n",
    "for result in results:\n",
    "    # If the result is a CSV string, parse it\n",
    "    if isinstance(result, str) and \",\" in result:\n",
    "        # Split the CSV string into values, being careful with quoted values\n",
    "        values = []\n",
    "        current_value = \"\"\n",
    "        quote_count = 0\n",
    "        \n",
    "        for char in result:\n",
    "            if char == '\"':\n",
    "                quote_count += 1\n",
    "                if quote_count % 6 == 0:  # Handle triple double quotes\n",
    "                    current_value += char\n",
    "            elif char == ',' and quote_count % 6 == 0:  # Only split on commas outside quotes\n",
    "                values.append(current_value.strip())\n",
    "                current_value = \"\"\n",
    "            else:\n",
    "                current_value += char\n",
    "                \n",
    "        # Add the last value\n",
    "        values.append(current_value.strip())\n",
    "        \n",
    "        # Clean up the values - remove excessive quotes\n",
    "        values = [v.strip('\"\"\"') for v in values]\n",
    "        \n",
    "        # Create a dictionary with column names and values\n",
    "        row_dict = {col: val for col, val in zip(columns, values)}\n",
    "        processed_results.append(row_dict)\n",
    "    else:\n",
    "        # If not a CSV string, just add as is\n",
    "        processed_results.append({\"raw_result\": result})\n",
    "\n",
    "# Replace the original results with the processed ones\n",
    "results = processed_results\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(output_csv, index=False)\n",
    "# Add timestamp to create a versioned output file\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "versioned_output_csv = f\"{output_csv.split('.')[0]}_{timestamp}.csv\"\n",
    "\n",
    "# Save both versioned and standard output\n",
    "df.to_csv(versioned_output_csv, index=False)\n",
    "print(f\"Results saved to {output_csv} and versioned copy at {versioned_output_csv}\")\n",
    "\n",
    "# Display results\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
